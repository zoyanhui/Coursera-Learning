q3_merge <- arrange(m, desc(Ranking))
q3_merge[13,3]
sum(!is.na(unique(m$Ranking)))
q3_merge <- m; q3_merge$Ranking <- as.numeric(as.character(q3_merge$Ranking))
q3_merge <- arrange(q3_merge, desc(Ranking))
q3_merge[13,3]
income_group <- group_by(q3_merge, Income.Group)
summarise(income_group, avg = mean(Ranking, na.rm = TRUE))
summarise(groups, avg = mean(Ranking, na.rm = TRUE))
groups <- group_by(m, Income.Group)
summarise(groups, avg = mean(Ranking, na.rm = TRUE))
?cut
cut(x, breaks = 5)
cut(m, breaks = 5)
cut(m$Ranking, breaks = 5)
head(m)
cut(m$Ranking, breaks = 5)
m$RankGroup <- cut(m$Ranking, breaks = 5)
table(m$RankGroup, m$Income.Group)
pwd()
getwd()
cd("..")
setwd("..")
dir.create("course-project")
setwd("course-project/")
dir()
getwd()
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip", destfile = "getdata.zip", method="curl")
getwd()
dir()
dir()
dir()
x <- "please help me"
x[1]
x[[1]]
split(x)
?split
split(x, x == ' ')
split(x, which(x == ' '))
x == ' '
strsplit(x, " ")
splitNames <- strsplit(x, " ")
class(splitNames)
names(splitNames)
splitNames
?strsplit
test <- "this_is_a_test"
sub("_", "", test)
gsub("_", "", test)
gsub("_", "-", test)
grep("test", test)
grep("test", strsplit(test, "_"))
strsplit(test, "_")
grep("test", strsplit(test, "_"))
grep("test", strsplit(test, "_"), value = TRUE)
grep("test", as.vector(strsplit(test, "_")))
as.vector(strsplit(test, "_"))
grep("test", strsplit(test, "_")[[1]])
grep("test", strsplit(test, "_")[[1]])
grep("test", strsplit(test, "_")[[1]], value = TURE)
grep("test", strsplit(test, "_")[[1]], value = TRUE)
grep("tes", strsplit(test, "_")[[1]], value = TRUE)
grepl("tes", strsplit(test, "_")[[1]], value = TRUE)
grepl("tes", strsplit(test, "_")[[1]])
table(grepl("tes", strsplit(test, "_")[[1]]))
strsplit(test, "_")[[1]])[!(grepl("tes", strsplit(test, "_")[[1]])),]
strsplit(test, "_")[[1]])[!(grepl("tes", strsplit(test, "_")[[1]]),]
strsplit(test, "_")[[1]])[!(grepl("tes", strsplit(test, "_"))[[1]]),]
(strsplit(test, "_")[[1]])[!(grepl("tes", strsplit(test, "_"))[[1]]),]
(strsplit(test, "_")[[1]])[!(grepl("tes", strsplit(test, "_")[[1]]),]
(strsplit(test, "_")[[1]])[!(grepl("tes", strsplit(test, "_")[[1]]))
,]
(strsplit(test, "_")[[1]])[!(grepl("tes", strsplit(test, "_")[[1]])),]
(strsplit(test, "_")[[1]])[!(grepl("tes", strsplit(test, "_")[[1]])),]
!(grepl("tes", strsplit(test, "_")[[1]]))
(strsplit(test, "_"))[[1]][!(grepl("tes", strsplit(test, "_")[[1]])),]
((strsplit(test, "_"))[[1]])[!(grepl("tes", strsplit(test, "_")[[1]])),]
((strsplit(test, "_"))[[1]])[!(grepl("tes", strsplit(test, "_")[[1]]))]
nchar(test)
substr(test, 1,3)
substr(test, 1,4)
paste(test, ' dd')
paste(test, 'dd')
paste0(test, 'dd')
str_trim(this)
str_trim(test)
str_trim(test+ " ")
str_trim(paste(test, " "))
ex.R
source("ex.R")
dir()
if(require("data.table"))
print 'x'
if(require("data.table")){}
if(require("data.table")){ print 'x'}
if(require("data.table")){ print('x')}
if(!require("data.table")){ print('x')}
?data.table
?melt
head(melt_data)
length(colnames(data))
length(data_labels)
melt(data, id = id_labels, measure.vars = c('tBodyAcc-mean()-X'))
nrow(melt(data, id = id_labels, measure.vars = c('tBodyAcc-mean()-X')))
tx<-melt(data, id = id_labels, measure.vars = c('tBodyAcc-mean()-X'))
unique(tx$variable)
unique(melt_data$variable)
?melt
names(airquality) <- tolower(names(airquality))
melt(airquality, id=c("month", "day"))
names(ChickWeight) <- tolower(names(ChickWeight))
melt(ChickWeight, id=2:4)
head(ChickWeight)
ChickWeight <- ChickWeight[1:6, ]
melt(ChickWeight, id=2:4)
melt(ChickWeight, id=3:4)
melt(ChickWeight, id=3:4, variable.name = "weight")
melt(ChickWeight, id=3:4, measure.vars =  = "weight")
melt(ChickWeight, id=3:4, measure.vars = "weight")
nrow(melt(ChickWeight, id=2:4))
nrow(melt_data)
nrow(data)
features <- read.table("./UCI HAR Dataset/features.txt")
head(features)
read.table("./UCI HAR Dataset/activity_labels.txt")
train_subjects <- read.table("./UCI HAR Dataset/train/subject_train.txt")
features <- read.table("./UCI HAR Dataset/features.txt")
activity_labels <- read.table("./UCI HAR Dataset/activity_labels.txt")
head(train_subjects)
train_x <- read.table("./UCI HAR Dataset/train/X_train.txt")
train_y <- read.table("./UCI HAR Dataset/train/y_train.txt")
# Load test subjects
test_subjects <- read.table("./UCI HAR Dataset/test/subject_test.txt")
# Load test data
train_x <- read.table("./UCI HAR Dataset/test/X_test.txt")
train_y <- read.table("./UCI HAR Dataset/test/y_test.txt")
head(train_y)
head(activity_labels)
tidy_data <- read.table("tidy_data.txt")
head(tidy_data)
features <- features[[,2]]
features <- features[,2]
head(features)
colnames(tidy_data)
head(activity_labels)
names(activity_labels)
colnames(activity_labels) <- c("activity_id", "activity_name")
names(activity_labels)
head(activity_labels)
# Load train subjects
train_subjects <- read.table("./UCI HAR Dataset/train/subject_train.txt")
# Load train data
train_x <- read.table("./UCI HAR Dataset/train/X_train.txt")
train_y <- read.table("./UCI HAR Dataset/train/y_train.txt")
# Load test subjects
test_subjects <- read.table("./UCI HAR Dataset/test/subject_test.txt")
# Load test data
test_x <- read.table("./UCI HAR Dataset/test/X_test.txt")
test_y <- read.table("./UCI HAR Dataset/test/y_test.txt")
head(train_y)
colnames(activity_labels) <- c("activity_id", "activity_name")
colnames(train_y) <- "activity_id"
train_y$activity_id <- activity_labels[train_y$activity_id,"activity_name"]
head(train_y)
colnames(train_y) <- "activity"
colnames(test_y) <- "activity"
test_y$activity_id <- activity_labels[test_y$activity,"activity_name"]
head(test_y)
# Load activity labels
activity_labels <- read.table("./UCI HAR Dataset/activity_labels.txt")
# Load train subjects
train_subjects <- read.table("./UCI HAR Dataset/train/subject_train.txt")
# Load train data
train_x <- read.table("./UCI HAR Dataset/train/X_train.txt")
train_y <- read.table("./UCI HAR Dataset/train/y_train.txt")
# Load test subjects
test_subjects <- read.table("./UCI HAR Dataset/test/subject_test.txt")
# Load test data
test_x <- read.table("./UCI HAR Dataset/test/X_test.txt")
test_y <- read.table("./UCI HAR Dataset/test/y_test.txt")
# 1. Merges the training and the test sets to create one data set.
## Apply feature names to X, both train_x and test_x
features <- features[,2]
colnames(train_x) <- features
colnames(test_x) <- features
## Apply activity name to Y, both train and test data
colnames(activity_labels) <- c("activity", "activity_name")
colnames(train_y) <- "activity"
train_y$activity <- activity_labels[train_y$activity,"activity_name"]
colnames(test_y) <- "activity"
test_y$activity <- activity_labels[test_y$activity,"activity_name"]
head(test_y)
head(test_x)
head(train_y)
head(subject_train)
cbind(subject_train, train_y, train_x)
cbind(subject_test, test_y, test_x)
train_data <-cbind(subject_train, train_y, train_x)
test_data <- cbind(subject_test, test_y, test_x)
head(train_data)
nrow(train_data)
nrow(test_data)
all_data <- rbind(train_data, test_data)
colnames(all_data)
?ggrep
?grepl
grep('(', "(hello)")
grep('\(', "(hello)")
grep('\\(', "(hello)")
extract_features <- grepl("mean\\(\\)|std\\(\\)", features)
head(extract_features)
extract_features <- grepl("mean|std", features)
head(extract_features)
extract_features <- grepl("mean\\(\\)|std\\(\\)", features)
extract_features <- features[grepl("mean\\(\\)|std\\(\\)", features)]
head(extract_features)
head(grepl("mean\\(\\)|std\\(\\)", features), 10)
length(colnames(all_data))
length(extract_features)
length(features)
all_data <- all_data[, cbind("subject", "activity", extract_features)]
c(extract_features, "subject", "activity")
extract_features
c(extract_features, "subject")
head(extract_features)
v <- c('1', '2')
c(v, '3')
c(v, 'subject')
class(extract_features)
as.vector(extract_features))
as.vector(extract_features)
all_data <- all_data[, c("subject", "activity", as.vector(extract_features))]
length(colnames(all_data))
all_data[2, "activity"]
## Load data features
features <- read.table("./UCI HAR Dataset/features.txt")
# Load activity labels
activity_labels <- read.table("./UCI HAR Dataset/activity_labels.txt")
# Load train subjects
train_subjects <- read.table("./UCI HAR Dataset/train/subject_train.txt")
# Load train data
train_x <- read.table("./UCI HAR Dataset/train/X_train.txt")
train_y <- read.table("./UCI HAR Dataset/train/y_train.txt")
# Load test subjects
test_subjects <- read.table("./UCI HAR Dataset/test/subject_test.txt")
# Load test data
test_x <- read.table("./UCI HAR Dataset/test/X_test.txt")
test_y <- read.table("./UCI HAR Dataset/test/y_test.txt")
# 1. Merges the training and the test sets to create one data set.
## Apply feature names to X, both train_x and test_x
features <- features[,2]
colnames(train_x) <- features
colnames(test_x) <- features
## Apply activity name to Y, both train and test data
colnames(train_y) <- "activity"
colnames(test_y) <- "activity"
## Combine x, y and subject
train_data <-cbind(subject_train, train_y, train_x)
test_data <- cbind(subject_test, test_y, test_x)
## Combine train and test data
all_data <- rbind(train_data, test_data)
# 2. Extracts only the measurements on the mean and standard deviation for each measurement.
extract_features <- features[grepl("mean\\(\\)|std\\(\\)", features)]
all_data <- all_data[, c("subject", "activity", as.vector(extract_features))]
# 3. Uses descriptive activity names to name the activities in the data set
colnames(activity_labels) <- c("activity", "activity_name")
all_data$activity <- activity_labels[all_data$activity,"activity_name"]
length(colnames(all_data))
all_data[2, "activity"]
?group_by
?dcast
?group_by
groups <- group_by(all_data, subject, activity)
head(groups)
summarise(groups, mean(fBodyAccJerk-mean()-Z ))
summarise(groups, mean(fBodyAccJerk-mean()-Z))
summarise(groups, mean('fBodyAccJerk-mean()-Z'))
?dcast
tidy_data   = dcast(melt_data, subject + Activity_Label ~ variable, mean)
write.table(tidy_data, file = "./tidy_data2.txt")
write.table(tidy_data, file = "./tidy_data2.txt", row.name=FALSE)
write.table(tidy_data, file = "./tidy_data2.txt", row.name=FALSE)
?melt
rm(list=ls())
source('run_analysis.R')
?group_by
gs <- group_by(all_data, subject, activity)
class(gs)
?summarise
cols <- setdiff(colnames(all_data), c("subject","activity"))
ddply(gs, function(g){
for(col in cols){
return
}
)
dfx <- data.frame(
group = c(rep('A', 8), rep('B', 15), rep('C', 6)),
sex = sample(c("M", "F"), size = 29, replace = TRUE),
age = runif(n = 29, min = 18, max = 54)
)
dfx
ddply(dfx, .(group, sex), summarize,
mean = round(mean(age), 2),
sd = round(sd(age), 2))
x <- ddply(dfx, .(group, sex), summarize,
mean = round(mean(age), 2),
sd = round(sd(age), 2))
ddply(x, .(group,sex), mean)
x
ddply(x, .(group,sex), function(e){print(e)})
rbind(x, c( group='C',sex='M', mean='0.12' sd='4.35'))
rbind(x, c( group='C',sex='M', mean='0.12' ,sd='4.35'))
ddply(x, .(group,sex), function(e){print(e)})
x <- rbind(x, c( group='C',sex='M', mean='0.12' ,sd='4.35'))
ddply(x, .(group,sex), function(e){print(e)})
cols <- c('mean', 'sd')
ddply(x, .(group,sex), function(e){ mean(e[,cols])})
ddply(x, .(group,sex), function(e){ print(e[,cols])})
ddply(x, .(group,sex), function(e){ mean(e[,cols], dim=2)})
ddply(x, .(group,sex), function(e){ class(e[,cols])})
ddply(x, .(group,sex), function(e){ class(e[[,cols]])})
ddply(x, .(group,sex), ~mean)
ddply(x, .(group,sex), ~mean, mean)
ddply(x, .(group,sex), c(mean(cols)))
ddply(x, .(group,sex), mean(cols))
x
ddply(x, .(group,sex), summarise, mean=mean(mean), sd=sd(sd)
)
colnames(x) <- c('group', 'sex', 'm',       'sd')
colnames(x) <- c('group', 'sex', 'm',       's')
ddply(x, .(group,sex), summarise, m=mean(m), s=sd(s)
)
ddply(x, .(group,sex), summarise, m=mean(m), s=sd(s))
x$m <- as.numeric(x$m)
x$s <- as.numeric(x$s)
x
ddply(x, .(group,sex), summarise, m=mean(m), s=sd(s))
ddply(x, .(group,sex), summarise, m=mean(m), s=mean(s))
ddply(x, .(group,sex), summarise, mean)
?aggregate
agrreaget(x, by=c('group', 'sex'), mean())
agrreaget(x, by=c('group', 'sex'), mean
)
aggreaget(x, by=c('group', 'sex'), mean)
aggregaet(x, by=c('group', 'sex'), mean)
aggregate(x, by=c('group', 'sex'), mean)
aggregate(x, by=as.list(c('group', 'sex')), mean)
aggregate(x)
aggregate(x, FUN = mean)
testDF <- data.frame(v1 = c(1,3,5,7,8,3,5,NA,4,5,7,9),
v2 = c(11,33,55,77,88,33,55,NA,44,55,77,99) )
by1 <- c("red", "blue", 1, 2, NA, "big", 1, 2, "red", 1, NA, 12)
by2 <- c("wet", "dry", 99, 95, NA, "damp", 95, 99, "red", 99, NA, NA)
aggregate(x = testDF, by = list(by1, by2), FUN = "mean")
testDF
rm(list=ls())
setwd("/Users/zhouyanhui/r-ws/getting-and-cleaning-data/week4-quiz")
data <- read.csv("getdata-data-ss06hid.csv")
head(data)
s <- strsplit(names(data), "wgtp")
s[123]
names(data)[123]
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
,destfile='getdata-data-GDP.csv', method='curl')
dir()
gdp_data <- read.csv("getdata-data-GDP.csv")
dim(gdp_data)
head(gdp_data)
gdp_data <- read.csv("getdata-data-GDP.csv", skip = 1)
head(gdp_data)
gdp_data <- read.csv("getdata-data-GDP.csv", skip = 3)
head(gdp_data)
?sub
gdp_data$US.dollars. <- gsub(",","", gdp_data$US.dollars.)
head(gdp_data)
gdp_data$US.dollars. <- as.numeric(gdp_data$US.dollars.)
mean(gdp_data$US.dollars., rm.na=TRUE)
mean(gdp_data$US.dollars., na.rm=TRUE)
gdp_data <- read.csv("getdata-data-GDP.csv", skip = 3)
head(gdp_data)
mean(gdp_data$US.dollars., na.rm=TRUE)
gdp_data$US.dollars. <- as.numeric(gdp_data$US.dollars.)
head(gdp_data)
gdp_data <- read.csv("getdata-data-GDP.csv", skip = 3)
head(gdp_data)
gdp_data$US.dollars. <- gsub(",","", gdp_data$US.dollars.)
head(gdp_data)
mean(gdp_data$US.dollars., na.rm=TRUE)
gdp_data$US.dollars. <- as.numeric(gdp_data$US.dollars.)
head(gdp_data)
mean(gdp_data$US.dollars., na.rm=TRUE)
dollar <- gdp_data$US.dollars.
dollar[complete.cases(dollar)]
mean(dollar[complete.cases(dollar)])
head(gdp_data, n=10)
gdp_data <- read.csv("getdata-data-GDP.csv", skip = 4, nrows = 215, stringsAsFactors = FALSE)
head(gdp_data)
gdp <- as.numeric(gsub(",", "", gdp_data$X.4))
mean(gdp, na.rm = TRUE)
sum1 <- sum(gdp)
sum1
sum1 <- sum(gdp, na.rm=TRUE)
sum1
gdp_data <- read.csv("getdata-data-GDP.csv", skip = 3)
head(gdp_data)
gdp2 <- as.numeric(gsub(",", "", gdp_data$US.dollars.))
identical(gdp, gdp2)
nrow(gdp)
length(gdp)
length(gdp2)
sum(gdp2, na.rm = TRUE)
71753960 - 71753960
71753960 - 296556885
gdp_data1 <- read.csv("getdata-data-GDP.csv", skip = 4, nrows = 215, stringsAsFactors = FALSE)
tail(gdp_data1)
grep("^United",gdp_data1$X.3)
edu_data <- read.csv(
"getdata-data-EDSTATS_Country.csv"
)
head(edu_data)
head(gdp_data1)
names(gdp_data1) <- c("CountryCode", "X1", "X2", "name", "x4")
head(gdp_data1)
library(plyr)
data <- join(gdp_data1, edu_data)
head(data)
colnames(data)
isFiscalYearEnd <- grepl("fiscal year end", tolower(data$Special.Notes))
isJune <- grepl("june", tolower(data$Special.Notes))
table(isFiscalYearEnd, isJune)
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
head(sampleTimes)
class(sampleTimes)
head(year(sampleTimes))
class(head(year(sampleTimes)))
which(year(sampleTimes) == 2012)
length(which(year(sampleTimes) == 2012))
length(which(year(sampleTimes) == 2012 & weekdays(sampleTimes) == 1))
head( weekdays(sampleTimes) )
class(head( weekdays(sampleTimes) ))
length(which(year(sampleTimes) == 2012 & weekdays(sampleTimes) == 'Monday'))
swirl()
library(swirl)
library(swirl)
swirl()
View(top_counts)
swirl()
swirl()
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
arrange(top_unique, desc(unique))
arrange(top_unique, desc(unique))
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit9)
submit()
submit()
submit()
View(result3)
submit()
submit()
submit()
submit()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
res<-gather(students2, sex_class, count)
res<-gather(students2, sex_class, count, -grade)
res
?separate
separate(res, sex_class, into=c("sex", "class"))
head(students2)
submit()
students3
?gather
submit()
?spread
head(students3)
submit()
submit()
submit()
extract_numeric("class5")
submit()
submit()
submit()
students4
submit()
submit()
head(stat_unique())
submit()
passwd
passed
failed
passed <- mutate(passed, status = "passed")
failed <- mutate(failed, status = "failed")
packageVersion('dplyr')
bind_rows(passwd, failed)
bind_rows(passed, failed)
sat
submit()
submit()
sumbit()
submit()
submit()
qq
